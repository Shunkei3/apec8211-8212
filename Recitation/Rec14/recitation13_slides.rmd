---
title: "APEC8212: Recitation 13"
author: 
  - "Shunkei Kakimoto" 
header-includes:
   - \usepackage{mathtools}
   - \usepackage{color}
   - \usepackage{amsmath}
output:
  xaringan::moon_reader:
    self_contained: true
    css: ../xaringan-themer.css 
    lib_dir: libs
    nature: 
      highlightStyle: github
      highlightLines: true
---
class: middle

```{r, child = '../setup.rmd', cache = FALSE}
```

```{r xaringan-scribble, echo=FALSE}
xaringanExtra::use_scribble()
```


```{r setup, include=FALSE, cache = FALSE}
options(htmltools.dir.version = FALSE)

# /*===== Reference =====*/
suppressMessages(library(RefManageR))

BibOptions(
  check.entries = FALSE,
  bib.style = "authoryear",
  style = "markdown",
  hyperlink = FALSE,
  dashed = TRUE,
  max.names = 2,
  longnamesfirst = FALSE
)
bib <- ReadBib("cite.bib")
```

```{r, include = F, cache = FALSE}
library(data.table)
library(ggplot2)
library(dplyr)
library(gganimate)
library(gifski)
library(gganimate)
# library(learnr)
```

```{r, include = F, eval=F, cache = FALSE}
httpgd::hgd()
httpgd::hgd_browse()
```

```{r xaringan-tachyons, echo=FALSE}
xaringanExtra::use_tachyons()
```

.content-box-green[**A Useful tip:**]

hitting letter "o" key will give you a panel view of the slides

---
class: middle

# Outline
1.[Review panel data analysis](#panel)

2.[Panel estimation with R](#R)

---
class: inverse, center, middle
name: panel

# Panel data analysis

<html><div style='float:left'></div><hr color='#EB811B' size=1px width=796px></html>

---
class: middle

# Panel (longitudinal) Data

.content-box-green[**Definition**]

Data follows the same individuals, families, firms, cities, states or whatever, across time

<br>

.content-box-green[**Example**]

+ Randomly select people from a population at a given point in time
+ Then the same people are re-interviewed at several subsequent points in time, which would result in data on wages, hours, education, and so on, for the same group of people in different years.

???
+ As you know, panel data follows the same individuals...

---
class: middle

Panel data have several attractive features: 

<span style="color:blue">`r Citet(bib, "kennedy2008guide")`</span>:

> 1. Panel data can be used to deal with heterogeneity in the micro units...
> 2. Panel data create more variability, through combining variation across micro units with variation over time,..... With this more informative data, more efficient estimation is possible. 
> 3. ...
> 4. Panel data allow better analysis of dynamic adjustment while cross-sectional data can tell us nothing about dynamics and time series data need to be very lengthy to provide good estimates of dynamic behavior .... Panel data avoid the need for a lengthy time series by exploiting information on the dynamic reactions of each of several units. 

???

+ With panel data, we can do lots of things that cross-sectional or time-series data cannot do. 
+ For example, we can address the problem of omitted variable bias by controlling for cross-sectional heterogeneity that might correlated with our key variables
+ Also, in addition to cross-sectional variation, temporal variation in panel data leads to more efficient estimation, and so on... 

---
class: middle

.content-box-green[**Central Question**]

Is there anything we can do to deal with endogeneity problem taking advantage of the panel data structure?


---
class: middle

# One-way error component model
Instead of this model, 
$$Y_{it} = X_{it}^{\prime} \beta + \color{blue}{e_{it}}$$

<p style="text-align: center;">&darr;</p>
We use this model, 
$$Y_{it} = X_{it}^{\prime} \beta + \color{blue}{u_{i} + \varepsilon_{it}}$$

+ $u_{i}$: an (time-invariant unobservable) individual-specific effect 
  * e.g., ability of individual $i$
+ $\varepsilon_{it}$: idiosyncratic errors 


.content-box-green[**Idea:**]

+ We model each $u_i$ as a different intercept for each cross-sectional unit.
  * Random effects model
  * Fixed effects model 

???
+ This motivates the one-way error component model. 
+ Now we decomposes the error term $e_{it}$ into the two parts, which are individual-specific effect and an idiosyncratic errors. 
+ The idea is that we want to model each $u_i$ as a different intercept for each cross-sectional unit. There are mainly two modeling approach to do this. 

---
class: middle

# Fixed effect model

[Mundlak (1961)](https://www.jstor.org/stable/1235460)

$$Y_{it} = X_{it}^{\prime} \beta + \color{blue}{u_{i} + \varepsilon_{it}}$$

+ Now, we assume that $u_{i}$ is correlated with $X_{it}$. Then, $u_{i}$ is called a **fixed effect**,

.content-box-green[**Idea:**]
+ Put in a dummy for each individual and run OLS (this is called least squares dummy variables, LSDV) 
  * This allows for each individual to have a different intercept. 
+ Algebraically, this is equivalent to within-transformation (i.e., subtracting the individual-specific mean from the variables). 


???
+ These individual dummies absorb whatever individual specific effects, therefore it immunes to omitted variable bias. 


---
class: middle

# Fixed effect model

[Mundlak (1961)](https://www.jstor.org/stable/1235460)

$$Y_{it} = X_{it}^{\prime} \beta + \color{blue}{u_{i} + \varepsilon_{it}}$$

+ Now, we assume that $u_{i}$ is correlated with $X_{it}$. Then, $u_{i}$ is called a **fixed effect**,

.content-box-green[**Idea:**]
+ Put in a dummy for each individual and run OLS (this is called least squares dummy variables, LSDV) 
  * This allows for each individual to have a different intercept. 
+ Algebraically, this is equivalent to within-transformation (i.e., subtracting the individual-specific mean from the variables). 

<br>

.content-box-green[**Drawback:**]
+ By including bunch of individual dummies, we loss lots of degree of freedom &rarr; inefficient estimate
+ We cannot estimate the coefficients on time-invariant variables (e.g., gender, race, or religion)

???
+ Meanwhile, there are some drawbacks. By including bunch of individual dummies, we loss lots of degree of freedom. For example, if we have 1000 dummies, then we lose 999 degrees of freedom. So, compared to the RE model, FE models are inefficient. 
+ Also, since within-transformation wipes out any time-invariant factors, so fixed effects model does not allow us to estimate coefficients on time-invariant variables such as gender, race, or religion. This might be a problematic, if you are interested in measuring discrimination. 
+ but we can recover the such coefficients using IV estimator, which will be covered in the next semester. 

---
class: middle

## Critical assumption for the unbiasedness of FE estimator

.content-box-red[**Assumption**]

Strict exogeneity:
$$E[\varepsilon_{it}|\mathbf{X}_{it}]=0$$

**Verbally**: The idiosyncratic errors is mean independent of all explanatory variables in all time period. 

---
class: middle

## Critical assumption for the unbiasedness of FE estimator

.content-box-red[**Assumption**]

Strict exogeneity:
$$E[\varepsilon_{it}|\mathbf{X}_{it}]=0$$

**Verbally**: The idiosyncratic errors is mean independent of all explanatory variables in all time period. 

<br>

.content-box-green[**Question:**]
+ 


---
class: middle

## Fixed effects estimator vs Differenced estimator

.content-box-green[**Differenced estimator**]


Supplement of slides 22 in Lecture note on panel data:

The relative efficiency of FE and FD estimators depend on the degree of serial correlation in the idiosyncratic errors ($Corr(\varspsilon_{i,t}, \varspsilon_{i,t-1})$).

+ If the errors are serially uncorrelated ($Corr(\varspsilon_{i,t}, \varspsilon_{i,t-1})=0$), the FE estimator is more efficient
+ If the errors follow a random walk, the FD estimator is more efficient. 


???
+ Fixed effects estimator is 


---
class: middle

# Dynamic panel models

Don't worry, we will learn the details in APEC 8213. 


---
class: middle

Lots of interesting discussions on fixed effects estimation for causal inference are going on. For example, 

[Imai and Kim (2019)](https://onlinelibrary.wiley.com/doi/abs/10.1111/ajps.12417)

[Imai and Kim (2021)](https://www.cambridge.org/core/journals/political-analysis/article/abs/on-the-use-of-twoway-fixed-effects-regression-models-for-causal-inference-with-panel-data/F10006D0210407C5F9C7CAC1EEE3EF0D)

[Millimet and Bellemare (2023)](https://docs.iza.org/dp16202.pdf)

<br>

In the context of climate economics, 

[Blanc and Schlenker (2017)](https://www.journals.uchicago.edu/doi/abs/10.1093/reep/rex016?journalCode=reep)

???
+ Okay, these are very basic econometric facts about fixed effects estimations. Fixed effect estimation can remove any time-invariant unobserved individual specific-effects, therefore it is immune to the endogeneity problem. Great. But this is a truly theoretical point of view. 
+ From the application point of view, I feel like we need to think more carefully about the operation that the fixed effect is implicitly invoking. 
+ I feel like this, because there are lots of interesting discussion about fixed effect estimator are going on in recent years. 
+ For longer time period, say 20 years, time-invariant factors that we assume might not be actually time-invariant. For example, people's preference.

+ Causal inference is all about the question of how to credibly estimate the counterfactual outcomes through the comparison of treated and control observations

+ For example, after the within-transformation, what kind of variations are left? Is it the variation what we want or not?
+ In the context of climate economics, fixed effect model has been used a lot utilizing the exogeneity of the realization of weather. But, within-transformation, in other words, demeaning  the means   the main goal is to understand the correct damage function of climate to project what would be the future impact of climate change. 


---
class: inverse, center, middle
name: R

# Panel estimation with R

<html><div style='float:left'></div><hr color='#EB811B' size=1px width=796px></html>

---
class: middle

In the class we use `plm` package. 

```{r, eval=FALSE}
# === Install R package === #
install.packages("plm")
```

<br>

.content-box-green[**Other options:**]

+ `feols()` function from `fixest` package 

---
class: middle 

## Preparation

```{r}
library(plm)

# === Load Data === #
library(stargazer)
library(AER)
data(Fatalities)
# --- data.table (you don't need to) --- #
setDT(Fatalities)
```

```{r, eval=F}
# === Take a look at the data === #
head(Fatalities)
# === See the information about the data  === #
?Fatalities
```

Define the traffic fatality rate, measured as the number of fatalities per 10000 inhabitants. 
```{r}
# --- Define the fatality rate --- #
Fatalities[,fatal_rate:= fatal/pop*10000]
# or you can do with 
# Fatalities$fatal_rate <- Fatalities$fatal/Fatalities$pop * 10000
```

---
class: middle

.content-box-green[**Syntax:**]

**Step1**: Use `pdata.frame()` to tell R that the data is panel data. 

```{r}
panel_fatalities <- pdata.frame(Fatalities, index=c("state", "year"))
```
 + In `index=`, specify which columns indicate the individual and time indexes 

<br>

**Step2**: Use `plm()` to tell R that the data is panel data. 

```{r}
# Estimate the impact of beer tax (adjusted for 1988 dollars) and the traffic fatality rate

# === Pooled OLS === #
po_reg <- plm(fatal_rate ~ beertax, data = panel_fatalities, model = "pooling")

# === Random effects model === #
re_reg <- plm(fatal_rate ~ beertax| x+y, data = panel_fatalities, model = "random")

# === Fixed effects model === #
fe_reg <- plm(fatal_rate ~ beertax, data = panel_fatalities, model = "within")

# === First difference === #
fd_reg <- plm(fatal_rate ~ beertax, data = panel_fatalities, model = "fd")
```


---
class: middle

```{r, results="asis"}
stargazer(
  po_reg, re_reg, fe_reg, fd_reg,
  type="html"
  )
```








